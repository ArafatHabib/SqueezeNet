{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3YonGv5Cmv"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmey0raWKIvV"
      },
      "source": [
        "data_dir1=r'/content/drive/MyDrive/train/Concrete Data'\r\n",
        "data_dir2=r'/content/drive/MyDrive/validation'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bLeQm-MKcP1",
        "outputId": "55c4abdf-a994-48a8-ed43-0cb6b458ce3c"
      },
      "source": [
        "import pathlib\r\n",
        "batch_size = 32\r\n",
        "img_height = 180\r\n",
        "img_width = 180\r\n",
        "\r\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir1,\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir2,\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Using 1600 files for training.\n",
            "Found 384 files belonging to 2 classes.\n",
            "Using 76 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZqtLCuvLGwl",
        "outputId": "7af7a2f6-b606-4bc2-ae82-8e34fcea53b8"
      },
      "source": [
        "class_names = train_ds.class_names\r\n",
        "print(class_names)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Negative', 'Positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuy8zlSXLKo2"
      },
      "source": [
        "UTOTUNE = tf.data.AUTOTUNE\r\n",
        "\r\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=UTOTUNE)\r\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=UTOTUNE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mONnK_I-Nj5F"
      },
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\r\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\r\n",
        "first_image = image_batch[0]\r\n",
        "# Notice the pixels values are now in `[0,1]`.\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaArANX8NoSl"
      },
      "source": [
        "import keras\r\n",
        "import keras.backend as K\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\r\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\r\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\r\n",
        "\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "from time import time\r\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7x3MjDQQdhO"
      },
      "source": [
        "def squeezenet(input_shape, n_classes):\r\n",
        "  \r\n",
        "  def fire(m, fs, fe):\r\n",
        "    s = Conv2D(fs, 1, activation='relu')(m)\r\n",
        "    e1 = Conv2D(fe, 1, activation='relu')(s)\r\n",
        "    e3 = Conv2D(fe, 3, padding='same', activation='relu')(s)\r\n",
        "    output = Concatenate()([e1, e3])\r\n",
        "    return output\r\n",
        "  \r\n",
        "  \r\n",
        "  input = Input(input_shape)\r\n",
        "  \r\n",
        "  m = Conv2D(96, 7, strides=2, padding='same', activation='relu')(input)\r\n",
        "  m = MaxPool2D(3, strides=2, padding='same')(m)\r\n",
        "  \r\n",
        "  m = fire(m, 16, 64)\r\n",
        "  m = fire(m, 16, 64)\r\n",
        "  m = fire(m, 32, 128)\r\n",
        "  m = MaxPool2D(3, strides=2, padding='same')(m)\r\n",
        "  \r\n",
        "  m = fire(m, 32, 128)\r\n",
        "  m = fire(m, 48, 192)\r\n",
        "  m = fire(m, 48, 192)\r\n",
        "  m = fire(m, 64, 256)\r\n",
        "  m = MaxPool2D(3, strides=2, padding='same')(m)\r\n",
        "  \r\n",
        "  m = fire(m, 64, 256)\r\n",
        "  m = Conv2D(n_classes, 1)(m)\r\n",
        "  m = GlobalAvgPool2D()(m)\r\n",
        "  \r\n",
        "  output = Activation('softmax')(m)\r\n",
        "  \r\n",
        "  model = Model(input, output)\r\n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bzfq8IvI5Ds"
      },
      "source": [
        "\r\n",
        "def alexnet(input_shape, n_classes):\r\n",
        "  input = Input(input_shape)\r\n",
        "  \r\n",
        "  # actually batch normalization didn't exist back then\r\n",
        "  # they used LRN (Local Response Normalization) for regularization\r\n",
        "  x = Conv2D(96, 11, strides=4, padding='same', activation='relu')(input)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = MaxPool2D(3, strides=2)(x)\r\n",
        "  \r\n",
        "  x = Conv2D(256, 5, padding='same', activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = MaxPool2D(3, strides=2)(x)\r\n",
        "  \r\n",
        "  x = Conv2D(384, 3, strides=1, padding='same', activation='relu')(x)\r\n",
        "  \r\n",
        "  x = Conv2D(384, 3, strides=1, padding='same', activation='relu')(x)\r\n",
        "  \r\n",
        "  x = Conv2D(256, 3, strides=1, padding='same', activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = MaxPool2D(3, strides=2)(x)\r\n",
        "  \r\n",
        "  x = Flatten()(x)\r\n",
        "  x = Dense(4096, activation='relu')(x)\r\n",
        "  x = Dense(4096, activation='relu')(x)\r\n",
        "  \r\n",
        "  output = Dense(n_classes, activation='softmax')(x)\r\n",
        "  \r\n",
        "  model1 = Model(input, output)\r\n",
        "  return model1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQxcKU9WQwG7",
        "outputId": "ce381b46-bd70-45c4-ec97-cf183528b436"
      },
      "source": [
        "'''\r\n",
        "input_shape=(img_height, img_width, 3)\r\n",
        "n_classes =2\r\n",
        "K.clear_session()\r\n",
        "model = squeezenet(input_shape, n_classes)\r\n",
        "model.summary()\r\n",
        "'''\r\n",
        "\r\n",
        "\r\n",
        "input_shape=(img_height, img_width, 3)\r\n",
        "n_classes =2\r\n",
        "K.clear_session()\r\n",
        "model1 = alexnet(input_shape, n_classes)\r\n",
        "model1.summary()\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 45, 45, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 45, 45, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 22, 22, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 22, 22, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 37,320,450\n",
            "Trainable params: 37,319,234\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_3OS7GRAdT"
      },
      "source": [
        "model1.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjGqRpxDUFEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7f7642-10e9-4ef1-b3be-2f63d59fb9be"
      },
      "source": [
        "epochs=5\r\n",
        "history = model1.fit(\r\n",
        "  train_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=epochs\r\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 201s 4s/step - loss: 12.7518 - accuracy: 0.8252 - val_loss: 20.4373 - val_accuracy: 0.5263\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 162s 3s/step - loss: 4.0521 - accuracy: 0.8985 - val_loss: 2.1697 - val_accuracy: 0.5526\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 161s 3s/step - loss: 0.0515 - accuracy: 0.9819 - val_loss: 0.4826 - val_accuracy: 0.9079\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 161s 3s/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.3654 - val_accuracy: 0.9211\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 163s 3s/step - loss: 0.0145 - accuracy: 0.9931 - val_loss: 0.1131 - val_accuracy: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}